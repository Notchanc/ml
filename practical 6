Aim: Using logistic regression to predict whether a credit card transaction is
fraudulent or not.

code=

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix

# Load the dataset
df = pd.read_csv("creditcard.csv")

# Exploratory Data Analysis
print(df.shape)
print(df.head())
print(df.isna().sum())
print(df.describe().round(2))

# Visualize the Class distribution
sns.barplot(x=df['Class'].value_counts().index, y=df['Class'].value_counts())
plt.show()

# Data Preprocessing
df = df.drop('Time', axis=1)
x = df.drop('Class', axis=1)
y = df['Class']

# Train-Test Split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)

# Model Building and Training
lr = LogisticRegression()
lr.fit(x_train, y_train)

# Model Prediction
y_pred = lr.predict(x_test)

# Evaluation
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))




use this code  


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler  # <--- Import the scaler

# Load the dataset
df = pd.read_csv("creditcard.csv")

# Exploratory Data Analysis
print(df.shape)
print(df.head())
print(df.isna().sum())
print(df.describe().round(2))

# Visualize the Class distribution
sns.barplot(x=df['Class'].value_counts().index, y=df['Class'].value_counts())
plt.show()

# Data Preprocessing
df = df.drop('Time', axis=1)
x = df.drop('Class', axis=1)
y = df['Class']

# ---> FIX: Scale the features <---
# Initialize the scaler
scaler = StandardScaler()
# Fit the scaler on the training data and transform it
x_train_scaled = scaler.fit_transform(x_train)
# Transform the test data using the SAME scaler (fitted on training data)
x_test_scaled = scaler.transform(x_test)

# Model Building and Training
# ---> FIX: Increase max_iter to ensure convergence <---
lr = LogisticRegression(max_iter=1000)  # Increased from default 100
lr.fit(x_train_scaled, y_train)  # Use scaled training data

# Model Prediction
y_pred = lr.predict(x_test_scaled)  # Use scaled test data

# Evaluation
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

